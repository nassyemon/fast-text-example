{"cells":[{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"import MeCab\nimport gensim\nimport sqlite3\nimport Levenshtein\nfrom scipy.stats.mstats import gmean\nimport functools\nfrom typing import Callable, Iterable, List, Set, Dict, Tuple, Optional"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"/Users/ec2-user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n  \"\"\"Entry point for launching an IPython kernel.\n"}],"source":"model = gensim.models.FastText.load_fasttext_format(\"./data/ja_model.bin\")"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":"conn = sqlite3.connect(\"./data/wnjpn.db\")"},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":"yomi = MeCab.Tagger(\"-Oyomi\")\nre_katakana = re.compile(r'[\\u30A1-\\u30F4]+')\ndef get_yomi(text: str) -> str:\n    reading = yomi.parse(text)\n    kana_readings = re_katakana.findall(reading)\n    return \"\".join(kana_readings)"},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":"[('優しい', 202105, 10.0, 10),\n ('暖か', 224808, 4.0, 4),\n ('温か', 180094, 4.0, 4),\n ('温かい', 230123, 4.0, 4),\n ('暖かい', 199016, 3.0, 3),\n ('親切', 181880, 3.0, 3),\n ('ソフト', 236122, 2.0, 2),\n ('懇ろ', 180938, 2.0, 2),\n ('懇篤', 179535, 2.0, 2),\n ('柔か', 159857, 2.0, 2),\n ('柔かい', 194787, 2.0, 2),\n ('柔らか', 215954, 2.0, 2),\n ('温和', 223289, 2.0, 2),\n ('篤い', 236818, 2.0, 2),\n ('親身', 193611, 2.0, 2),\n ('軟か', 214659, 2.0, 2),\n ('軟かい', 230984, 2.0, 2),\n ('軟らか', 237902, 2.0, 2),\n ('軟らかい', 195414, 2.0, 2),\n ('静やか', 190765, 2.0, 2),\n ('しなやか', 188485, 1.0, 1),\n ('たわやか', 221855, 1.0, 1),\n ('ねんごろ', 206005, 1.0, 1),\n ('もの柔か', 205072, 1.0, 1),\n ('もの柔らか', 206297, 1.0, 1),\n ('もの静か', 221200, 1.0, 1),\n ('やさしい', 238402, 1.0, 1),\n ('エレガンス', 200537, 1.0, 1),\n ('エレガント', 230934, 1.0, 1),\n ('ソフィスティケート', 184068, 1.0, 1),\n ('マイルド', 248428, 1.0, 1),\n ('上品', 235597, 1.0, 1),\n ('世話好き', 176471, 1.0, 1),\n ('人なつこい', 164339, 1.0, 1),\n ('人懐こい', 165333, 1.0, 1),\n ('人懐っこい', 157736, 1.0, 1),\n ('優婉', 183072, 1.0, 1),\n ('優美', 213541, 1.0, 1),\n ('優艶', 235083, 1.0, 1),\n ('優雅', 242151, 1.0, 1),\n ('典雅', 191265, 1.0, 1),\n ('典麗', 169868, 1.0, 1),\n ('円い', 171345, 1.0, 1),\n ('円か', 241943, 1.0, 1),\n ('厚い', 240948, 1.0, 1),\n ('嬋媛', 169054, 1.0, 1),\n ('寛雅', 169206, 1.0, 1),\n ('思いやりがある', 237820, 1.0, 1),\n ('愛想のいい', 193936, 1.0, 1),\n ('懐こい', 171924, 1.0, 1),\n ('懐っこい', 186801, 1.0, 1),\n ('手厚い', 192504, 1.0, 1),\n ('文雅', 206846, 1.0, 1),\n ('新切', 232581, 1.0, 1),\n ('暖い', 241360, 1.0, 1),\n ('柔い', 223539, 1.0, 1),\n ('柔らかい', 179621, 1.0, 1),\n ('流麗', 198249, 1.0, 1),\n ('深切', 175797, 1.0, 1),\n ('温い', 208523, 1.0, 1),\n ('瀟洒', 194518, 1.0, 1),\n ('物柔か', 219403, 1.0, 1),\n ('物柔らか', 163680, 1.0, 1),\n ('物静か', 219515, 1.0, 1),\n ('穏やか', 198962, 1.0, 1),\n ('穏便', 191588, 1.0, 1),\n ('穏和', 193962, 1.0, 1),\n ('窈窕たる', 225269, 1.0, 1),\n ('端麗', 230198, 1.0, 1),\n ('細やか', 195816, 1.0, 1),\n ('都雅', 195168, 1.0, 1),\n ('閑やか', 193395, 1.0, 1),\n ('閑麗', 244863, 1.0, 1),\n ('雅', 199534, 1.0, 1),\n ('雅びた', 202357, 1.0, 1),\n ('雅びやか', 176954, 1.0, 1),\n ('雅やか', 214484, 1.0, 1),\n ('雅馴', 238456, 1.0, 1),\n ('風雅', 211184, 1.0, 1),\n ('高雅', 172179, 1.0, 1),\n ('麗しい', 190428, 1.0, 1),\n ('麗しげ', 181169, 1.0, 1)]"},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":"def get_words_in_all_synsets(\n    search: str or Iterable[str], threshold: int = 1\n) -> List[Tuple[str, int, float, int]]:\n    placeholder = \"?\" if type(search) is str else \",\".join([\n        \"?\" for i in range(0, len(search))\n    ])\n    params = (search,threshold) if type (search) is str else [*search, threshold]\n    # print(placeholder, params)\n    cur = conn.execute(f\"\"\"\\\nselect\n sub.lemma,\n sub.wordid,\n sum(1.0) as score,\n count(sub.lemma) as occurrence\nfrom (\n    select\n        related_word.wordid,\n        related_word.lemma\n    from word base\n    inner join sense attributed_sense\n        on attributed_sense.wordid = base.wordid\n    inner join sense all_sense\n        on all_sense.synset = attributed_sense.synset\n    inner join word related_word\n        on related_word.wordid = all_sense.wordid\n        and related_word.lang = \"jpn\"\n    where base.lemma in ({placeholder})\n) sub\ngroup by sub.lemma, sub.wordid\nhaving count(sub.lemma) >= (?)\norder by count(sub.lemma) desc\n\"\"\", params)\n    return list(map(lambda x:(x[0:4]), cur.fetchall()))\n\n# get_words_in_all_synsets(\"優しい\", 1)\n# get_words_in_all_synsets([\"優しい\", \"好青年\", \"朗らか\"], 2)"},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":"def create_values_query(neigbhor_list: Iterable[Tuple[str, float]]):\n    params = functools.reduce(\n        lambda acc,e: { **acc, f\"w{e[0]}\": e[1][0], f\"s{e[0]}\": e[1][1] },\n        enumerate(neigbhor_list),\n        {}\n    )\n    query_elems = [f\":w{i}, :s{i}\" for i in range(0, len(neigbhor_list))]\n    return (f\"\"\"select {\" union select \".join(query_elems)} \"\"\", params)\n\ndef get_synonym_score_for_neigbhor_list(\n    neigbhor_list: Iterable[Tuple[str, float]],\n    threshold: int = 1,\n    includes_self: bool = True,\n) -> List[Tuple[str, int, float, int]]:\n    (values_query, params) = create_values_query(neigbhor_list)\n    query = f\"\"\"\\\nwith neigbhors(word, score) as (\n{values_query}\n),\nsub(word, score, wordid, lemma) as (\nselect\n  n.word,\n  n.score,\n  rel_w.wordid,\n  rel_w.lemma\nfrom neigbhors n\ninner join word w\n  on w.lemma = n.word\ninner join sense s\n  on s.wordid = w.wordid\ninner join sense rel_s\n  on rel_s.synset = s.synset\n  {\"\" if includes_self else \"and rel_s.wordid != s.wordid\" }\ninner join word rel_w\n  on rel_w.wordid = rel_s.wordid\n  and rel_w.lang = \"jpn\"\n)\nselect\n sub.lemma,\n sub.wordid,\n sum(sub.score) as score,\n count(sub.lemma) as occurrence\nfrom sub\ngroup by sub.lemma, sub.wordid\nhaving count(sub.lemma) >= :threshold\norder by count(sub.lemma) desc\\\n\"\"\"\n    cur = conn.execute(query, {**params, \"threshold\": threshold })\n    return list(map(lambda x:(x[0:4]), cur.fetchall()))\n\n# get_synonym_score_for_neigbhor_list([(\"優しい\",  0.1), (\"朗らか\", 0.01)])"},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":"def list_synonyms_from_similar_words(\n    search: str or Iterable[str],\n    topn: int=20,\n    threshold: int = 1,\n    includes_self: bool = False,\n) -> List[Tuple[str, float, int]]:\n    neigbhor_list= model.wv.most_similar(\n        positive=search,\n        topn=topn,\n    )\n    # display(neigbhor_list)\n    # similar_words = [*map(lambda x:x[0],neigbhor_list)]\n    synonyms = get_synonym_score_for_neigbhor_list(\n        neigbhor_list=neigbhor_list,\n        threshold=threshold,\n        includes_self=includes_self,\n    )\n    return synonyms\n\n# list_synonyms_from_similar_words(search=\"朗らか\")[0:30]"},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":"[('かわいい', 1.1521143794059754),\n ('可愛い', 1.0482676148414611),\n ('おしゃれ', 0.9552717208862305),\n ('愛らしい', 0.9444208502769471),\n ('シック', 0.7463299155235291),\n ('スタイリッシュ', 0.7463299155235291),\n ('小意気', 0.7463299155235291),\n ('小粋', 0.7463299155235291),\n ('瀟洒', 0.7463299155235291),\n ('御洒落', 0.7451115012168885)]"},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":"def get_mixed_synonyms(\n    search: str or Iterable[str],\n    search_threshold: int=1,\n    similar_topn: int=20,\n    similar_boost: float=0.2,\n    similar_threshold: int=1,\n    similar_includes_self: bool = True,\n    result_topn: int=50,\n) -> List[Tuple[str, float]]:\n    synoyms_from_search = get_words_in_all_synsets(\n        search=search,\n        threshold=search_threshold,\n    )\n    synonyms_from_similar_words = list_synonyms_from_similar_words(\n        search=search,\n        topn=similar_topn,\n        threshold=similar_threshold,\n        includes_self=similar_includes_self,\n    )\n    modified_score_from_similar_words = [\n        (word, wordid, similar_boost*score)\n        for (word, wordid, score, _) in synonyms_from_similar_words\n    ]\n    score_dict = functools.reduce(\n        lambda acc, x: {**acc, x[0]: (x[1] if x[0] not in acc else acc[x[0]]+ x[1]) },\n        synoyms_from_search + modified_score_from_similar_words,\n        {}\n    )\n    result_sorted = sorted(score_dict.items(), key=lambda x: x[1], reverse=True)\n    return result_sorted[0:result_topn]\n    \n# TODO: 同じ読み or ほぼ同じ読み　の単語を集約する\nget_mixed_synonyms(\"キュート\", result_topn=10)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":"0.64528024"},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":"def get_mixed_synonyms(\n    search: str or Iterable[str],\n    search_threshold: int=1,\n    similar_topn: int=20,\n    similar_boost: float=0.2,\n    similar_threshold: int=1,\n    similar_includes_self: bool = True,\n) -> List[Tuple[str, float]]:\n    synoyms_from_search = get_words_in_all_synsets(\n        search=search,\n        threshold=search_threshold,\n    )\n    synonyms_from_similar_words = list_synonyms_from_similar_words(\n        search=search,\n        topn=similar_topn,\n        threshold=similar_threshold,\n        includes_self=similar_includes_self,\n    )\n    modified_score_from_similar_words = [\n        (word, similar_boost*score) for (word, score, _) in synonyms_from_similar_words\n    ]\n    score_dict = functools.reduce(\n        lambda acc, x: {**acc, x[0]: (x[1] if x[0] not in acc else acc[x[0]]+ x[1]) },\n        synoyms_from_search + modified_score_from_similar_words,\n        {}\n    )\n    return sorted(score_dict.items(), key=lambda x: x[1], reverse=True)\n    \n# TODO: 同じ読み or ほぼ同じ読み　の単語を集約する\nget_mixed_synonyms(\"人柄\")"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"\ndisplay(get_words_in_all_synsets(\"明るい\"))\nsynonyms = list_synoyms_from_wordnet_dict(\"やる気\")\ndisplay(synonyms)\nlist_neigbhors_from_synonyms(synonyms, topn=20)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def list_neigbhors_from_synonyms(\n    synonyms: Iterable[Tuple[str, int]],\n    topn: int = 100\n):\n    multiplied_list = [[word for i in range(0,occurrence)] for (word, occurrence) in synonyms ]\n    search_list = [word for word_pack in multiplied_list for word in word_pack]\n    # display(search_list)\n    return list_neigbhors_for_search_list(search_list, topn=topn)\n"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def append_neigbhorness_lift_for_each_search(\n    search_list: Iterable[str],\n    word: str,\n    neigbhorness: float\n) -> List[Tuple[str, float, Tuple[float, float]]]:\n    neigbohr_and_lift = []\n    for search in search_list:\n        similarity = model.wv.similarity(word, search)\n        lift =  neigbhorness/similarity if similarity > 0 else 0\n        neigbohr_and_lift += [(similarity, lift)]\n    return (word, neigbhorness, neigbohr_and_lift)"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def filter_neigbours_by_score_func(\n    neigbhorness_lift: Iterable[Tuple[str, float, Tuple[float, float]]],\n    score_func: Callable[float, Iterable[Tuple[float, float]]]):\n"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"unexpected EOF while parsing (<ipython-input-14-bced9ec0ec98>, line 1)","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-bced9ec0ec98>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def get_related_words_with_lifts(search_list: list,\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"searches = [\"明るい\", \"性格\"]\ncombi = [\n   (word, score, [model.wv.similarity(word, search) for search in searches])\n   for (word, score) in model.wv.most_similar(\n       positive=searches,\n       topn=100\n    )\n]\ncoocs = [*filter(None, [\n    None if len([*filter(lambda x: x > score, search_scores)]) > 0 else\n    (\n        word,\n        score,\n        min([*map(lambda x:score/x, search_scores)]),\n        search_scores,\n    )\n    for (word, score, search_scores) in combi]\n)]\ndisplay(\"related\")\ndisplay([*sorted(coocs, key=lambda x:-x[2])][0:50])"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}