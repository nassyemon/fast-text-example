{"cells":[{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":"import re\nimport MeCab\nimport gensim\nimport sqlite3\nimport Levenshtein\nimport numpy as np\nfrom scipy.stats.mstats import gmean\nimport functools\nfrom typing import Callable, Iterable, List, Set, Dict, Tuple, Optional"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"/Users/ec2-user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n  \"\"\"Entry point for launching an IPython kernel.\n"}],"source":"model = gensim.models.FastText.load_fasttext_format(\"./data/ja_model.bin\")"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"conn = sqlite3.connect(\"./data/wnjpn.db\")"},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[],"source":"yomi = MeCab.Tagger(\"-Oyomi\")\nre_all_katakana = re.compile(r'^[\\u30A1-\\u30F4]+$')\ndef get_yomi(text: str) -> str:\n    # TODO return None if yumi parse failed\n    reading = yomi.parse(text).replace(\"\\n\", '')\n    matched = re_all_katakana.match(reading)\n    if matched:\n        return matched[0]\n    return None"},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[],"source":"## returns a list of\n## (wordid: int, lemma: str,score: float, occurrence: int)\ndef get_words_in_all_synsets(\n    search: str or List[str],\n    threshold: int = 1\n) -> List[Tuple[int, str, float, int]]:\n    placeholder = \"?\" if type(search) is str else \",\".join([\n        \"?\" for i in range(0, len(search))\n    ])\n    params = (search,threshold) if type (search) is str else [*search, threshold]\n    # print(placeholder, params)\n    cur = conn.execute(f\"\"\"\\\nselect\n sub.wordid,\n sub.lemma,\n sum(1.0) as score,\n count(sub.lemma) as occurrence\nfrom (\n    select\n        related_word.wordid,\n        related_word.lemma\n    from word base\n    inner join sense attributed_sense\n        on attributed_sense.wordid = base.wordid\n    inner join sense all_sense\n        on all_sense.synset = attributed_sense.synset\n    inner join word related_word\n        on related_word.wordid = all_sense.wordid\n        and related_word.lang = \"jpn\"\n    where base.lemma in ({placeholder})\n) sub\ngroup by sub.lemma, sub.wordid\nhaving count(sub.lemma) >= (?)\norder by count(sub.lemma) desc\n\"\"\", params)\n    return list(map(lambda x:(x[0:4]), cur.fetchall()))\n\n# get_words_in_all_synsets(\"優しい\", 1)\n# get_words_in_all_synsets([\"優しい\", \"好青年\", \"朗らか\"], 2)"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def create_values_query(\n    neigbhor_list: Iterable[Tuple[str, float]]\n) -> Tuple[str, Dict]:\n    params = functools.reduce(\n        lambda acc,e: { **acc, f\"w{e[0]}\": e[1][0], f\"s{e[0]}\": e[1][1] },\n        enumerate(neigbhor_list),\n        {}\n    )\n    query_elems = [f\":w{i}, :s{i}\" for i in range(0, len(neigbhor_list))]\n    return (f\"\"\"select {\" union select \".join(query_elems)} \"\"\", params)\n\n## returns a list of\n## (wordid: int, lemma: str,score: float, occurrence: int)\ndef get_synonym_score_for_neigbhor_list(\n    neigbhor_list: Iterable[Tuple[str, float]],\n    threshold: int = 1,\n    includes_self: bool = False,\n) -> List[Tuple[str, int, float, int]]:\n    (values_query, params) = create_values_query(neigbhor_list)\n    query = f\"\"\"\\\nwith neigbhors(word, score) as (\n{values_query}\n),\nsub(word, score, wordid, lemma) as (\nselect\n  n.word,\n  n.score,\n  rel_w.wordid,\n  rel_w.lemma\nfrom neigbhors n\ninner join word w\n  on w.lemma = n.word\ninner join sense s\n  on s.wordid = w.wordid\ninner join sense rel_s\n  on rel_s.synset = s.synset\n  {\"\" if includes_self else \"and rel_s.wordid != s.wordid\" }\ninner join word rel_w\n  on rel_w.wordid = rel_s.wordid\n  and rel_w.lang = \"jpn\"\n)\nselect\n sub.wordid,\n sub.lemma,\n sum(sub.score) as score,\n count(sub.lemma) as occurrence\nfrom sub\ngroup by sub.lemma, sub.wordid\nhaving count(sub.lemma) >= :threshold\norder by count(sub.lemma) desc\\\n\"\"\"\n    cur = conn.execute(query, {**params, \"threshold\": threshold })\n    return list(map(lambda x:(x[0:4]), cur.fetchall()))\n\n# get_synonym_score_for_neigbhor_list([(\"優しい\",  0.1), (\"朗らか\", 0.01)])"},{"cell_type":"code","execution_count":153,"metadata":{},"outputs":[],"source":"## returns a list of\n## (wordid: int, lemma: str, score: float, occurrence: int)\ndef list_synonyms_from_similar_words(\n    search: str or List[str],\n    topn: int=20,\n    threshold: int = 1,\n    includes_self: bool = False,\n) -> List[Tuple[str, int, float, int]]:\n    neigbhor_list= model.wv.most_similar(\n        positive=search,\n        topn=topn,\n    )\n    # similar_words = [*map(lambda x:x[0],neigbhor_list)]\n    synonyms = get_synonym_score_for_neigbhor_list(\n        neigbhor_list=neigbhor_list,\n        threshold=threshold,\n        includes_self=includes_self,\n    )\n    return synonyms\n\n# list_synonyms_from_similar_words(search=[\"優しい\", \"かわいい\"])[0:30]"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def sort_by_score(\n    synonym_list: List[str],\n    top_n: int = -1,\n    order: str = \"asc\",\n) -> List[Dict]:\n    result_sorted = sorted(\n        synonym_list,\n        key=lambda x: x[\"s\"],\n        reverse=order==\"desc\",\n    )\n    if (top_n > 0 and type(top_n) == int):\n        return result_sorted[0:top_n]\n    return result_sorted\n\ndef get_mixed_synonyms(\n    search: str or Iterable[str],\n    search_threshold: int=1,\n    use_similar: bool=True,\n    similar_topn: int=20,\n    similar_boost: float=0.2,\n    similar_threshold: int=1,\n    similar_includes_self: bool = False,\n    add_yomi: bool = True,\n) -> List[Dict]:\n    synoyms_from_search = get_words_in_all_synsets(\n        search=search,\n        threshold=search_threshold,\n    )\n    synonyms_from_similar_words = list_synonyms_from_similar_words(\n        search=search,\n        topn=similar_topn,\n        threshold=similar_threshold,\n        includes_self=similar_includes_self,\n    ) if use_similar else []\n    aggregated_dict = functools.reduce(\n        lambda acc, x: {\n            **acc, x[0]: (\n                {\n                    \"i\": x[0], # wordid\n                    \"w\": x[1], # word (lemma)\n                    \"s\": x[2], # score\n                    \"occ\": x[3], # occurrence in search iteself\n                    \"sim_occ\": 0, # occurrence in similar words\n                } if x[0] not in acc else {\n                    **acc[x[0]],\n                    \"s\": acc[x[0]][\"s\"] + x[2],\n                    \"occ\": acc[x[0]][\"occ\"] + x[3],\n                }\n            )\n        },\n        synoyms_from_search,\n        {}\n    )\n    if not use_similar:\n        return aggregated_dict.values()\n    return functools.reduce(\n        lambda acc, x: {\n            **acc, x[0]: (\n                {\n                    \"i\": x[0],\n                    \"w\": x[1],\n                    \"s\": similar_boost*x[2],\n                    \"occ\": 0,\n                    \"sim_occ\": x[3],\n                } if x[0] not in acc else {\n                    **acc[x[0]],\n                    \"s\": acc[x[0]][\"s\"] + similar_boost*x[2],\n                    \"sim_occ\": acc[x[0]][\"sim_occ\"] + x[3],\n                }\n            )\n        },\n        synonyms_from_similar_words,\n        aggregated_dict,\n    ).values()\n\n# sort_by_score(get_mixed_synonyms(\"綺麗な\", use_similar=True), 10)"},{"cell_type":"code","execution_count":154,"metadata":{},"outputs":[],"source":"def get_top_n_percentile(\n    synonym_list: List[str],\n    percentile: float = 0.95,\n) -> List[Dict]:\n    sorted_list = sort_by_score(synonym_list, order=\"desc\")\n    score_list = [*map(lambda x:x[\"s\"], sorted_list)]\n    total_score = sum(score_list)\n    until = percentile * total_score\n    curr = 0.0\n    for i,s in enumerate(score_list):\n        curr += s\n        if (curr >= until):\n            break\n    return sorted_list[0:i]\n\n# get_top_n_percentile(get_mixed_synonyms(\"綺麗な\", use_similar=True), percentile=0.95)\n"},{"cell_type":"code","execution_count":155,"metadata":{},"outputs":[],"source":"def get_similar_yomi_table(\n    yomi_list: List[str],\n    prefix_weight: float = 0.05,\n    threshold: float = 0.90\n):\n    n = len(yomi_list)\n    parent = [-1] * n\n    root_word = [None] * n\n    sim_links = []\n    for i, w_i in enumerate(yomi_list):\n        sims = []\n        for  j, w_j in enumerate(yomi_list[i+1:], i+1):\n            if parent[j] >= 0:\n                continue\n            dist = Levenshtein.jaro_winkler(w_i, w_j, prefix_weight)\n            if dist < threshold:\n                continue\n            parent[j] = i\n            root_word[j] = yomi_list[i] if parent[i] < 0 else root_word[i]\n            sims += [(j, w_j, dist)]\n        if parent[i] < 0 or len(sims) > 0:\n            sim_links += [(i, w_i, parent[i], sims)]\n        else:\n            sim_links += [None]\n    # display(sim_links)\n    # similar_yomi_dict = [(yomi_list[i], root_word[i]) for i in range (0, n)]\n    translate_dict = dict([\n        (yomi_list[i], root_word[i] if root_word[i] is not None else yomi_list[i])\n        for i in range (0, n)\n    ])\n    yomi_table = functools.reduce(\n        lambda acc, x: {\n            **acc,\n            x[1]: [x[0]] if x[1] not in acc else [*acc[x[1]], x[0]]\n        }, translate_dict.items(), {})\n    return yomi_table, sim_links\n\n#get_similar_yomi_table([\"キレイナ\", \"キレイダ\", \"キレイ\", \"キタナイ\", \"キレイダヨ\", \"キレイダヨネ\", \"レイダヨ\", \"ソケナイ\", \"キレタ\", \"ソッケナイ\"])"},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[],"source":"def get_yomi_lookup(synonym_list: List[str]):\n    with_yomi = []\n    for x in synonym_list:\n        yomi = get_yomi(x[\"w\"])\n        if yomi is None or len(yomi) < 1:\n            continue\n        with_yomi += [{**x, \"y\": yomi }]\n    return functools.reduce(lambda acc, x: {\n        **acc,\n        x[\"y\"]: (acc[x[\"y\"]] if x[\"y\"] in acc else []) + [x]\n    }, with_yomi, {})\n\ndef get_representative_word(\n    search: str or List[str],\n    items: Iterable[Dict],\n):\n    if len(items) < 1:\n        return (None, None)\n    if len(items) == 1:\n        return (items[0], [])\n    max_score = max(map(lambda x:x[\"s\"], items))\n    ties = [*filter(lambda x:x[\"s\"] >= max_score, items)]\n    if len(ties) < 2:\n        rep = ties[0]\n        return (rep, [*filter(lambda x:x[\"i\"] != rep[\"i\"], items)])\n    sim_score = [*map(lambda x: (x, np.mean(model.wv.similarity(search, x[\"w\"]))), ties)]\n    top_sim_score = max(map(lambda x:x[1], sim_score))\n    score_sorted = sorted(sim_score, key=lambda x: x[1], reverse=True)\n    rep = score_sorted[0][0]\n    return (rep, [*filter(lambda x:x[\"i\"] != rep[\"i\"], items)])\n\ndef aggregate_score(items: Iterable[Dict]):\n    scores = [*map(lambda x:x[\"s\"], items)]\n    return sum(scores)\n\ndef aggregate_by_yomi(\n    search: str or List[str],\n    synonym_list: List[str],\n    top_n: int = 20,\n    use_similar_yomi: bool = True,\n    remove_self: bool = True,\n    jaro_winkler_prefix_weight: float = 0.05,\n    jaro_winkler_threshold: float = 0.95,\n):\n    yomi_lookup = get_yomi_lookup(synonym_list)\n    unique_yomi_list = [yomi for yomi in yomi_lookup.keys() if yomi != '']\n    if use_similar_yomi:\n        yomi_table,_ = get_similar_yomi_table(\n            unique_yomi_list,\n            prefix_weight = jaro_winkler_prefix_weight,\n            threshold = jaro_winkler_threshold,\n        )\n    else:\n        yomi_table = dict([(yomi, yomi) for yomi in unique_yomi_list])\n    TODO = None\n    yomi_aggregated = []\n    for yomi, similar_yomis in yomi_table.items():\n        items = sum([yomi_lookup[sim_y] for sim_y in similar_yomis], [])\n        (rep, others) = get_representative_word(search, items)\n        agg_score = aggregate_score(items)\n        yomi_aggregated += [{\n            \"i\": rep[\"i\"],\n            \"w\": rep[\"w\"],\n            \"y\": rep[\"y\"],\n            \"s\": agg_score,\n            \"c\": [*map(lambda x: ({\"i\": x[\"i\"], \"w\": x[\"w\"]}), others)]\n        }]\n    \n    if remove_self and type(search) == str:\n        self_yomi = get_yomi(search)\n        yomi_aggregated = [*filter(lambda x: x[\"y\"] != self_yomi, yomi_aggregated)]\n    if remove_self and type(search) == list:\n        self_yomis = [get_yomi(s) for s in search]\n        yomi_aggregated = [*filter(lambda x: x[\"y\"] not in self_yomis, yomi_aggregated)]\n\n    agg_sorted = sorted(yomi_aggregated, key=lambda x:x[\"s\"], reverse=True)\n    if top_n <= 0:\n        return agg_sorted\n    return agg_sorted[0: top_n]\n\n# tops = get_top_n_percentile(get_mixed_synonyms([\"優しい\"], use_similar=True), percentile=0.95)\n# display(aggregate_by_yomi([\"優しい\"],tops))"},{"cell_type":"code","execution_count":176,"metadata":{},"outputs":[{"data":{"text/plain":"[{'i': 233947,\n  'w': '聡い',\n  'y': 'サトイ',\n  's': 5.423588463664054,\n  'c': [{'i': 200930, 'w': '敏い'}, {'i': 205736, 'w': 'さとい'}]},\n {'i': 220718, 'w': '利口', 'y': 'リコウ', 's': 5.368125593662262, 'c': []},\n {'i': 159313, 'w': '賢しい', 'y': 'サカシイ', 's': 4.513119414448738, 'c': []},\n {'i': 175664, 'w': '利発', 'y': 'リハツ', 's': 4.331093329191208, 'c': []},\n {'i': 194582, 'w': '賢明', 'y': 'ケンメイ', 's': 4.324983194470406, 'c': []},\n {'i': 155461, 'w': '利巧', 'y': 'リタクミ', 's': 3.5110827028751372, 'c': []},\n {'i': 180732, 'w': '明敏', 'y': 'メイビン', 's': 3.420624279975891, 'c': []},\n {'i': 228131, 'w': '怜悧', 'y': 'レイリ', 's': 3.373590224981308, 'c': []},\n {'i': 240131, 'w': '穎悟', 'y': 'エイゴ', 's': 3.373590224981308, 'c': []},\n {'i': 235106, 'w': '聡明', 'y': 'ソウメイ', 's': 3.371486783027649, 'c': []},\n {'i': 159024, 'w': '英明', 'y': 'エイメイ', 's': 3.2815588265657425, 'c': []},\n {'i': 171371, 'w': '利根', 'y': 'リコン', 's': 2.2790583789348604, 'c': []},\n {'i': 241484, 'w': '明達', 'y': 'メイタツ', 's': 2.2790583789348604, 'c': []},\n {'i': 195721, 'w': '聡慧', 'y': 'サトトシ', 's': 2.2790583789348604, 'c': []},\n {'i': 205084, 'w': '英悟', 'y': 'エイサトル', 's': 2.2340610355138777, 'c': []},\n {'i': 243525,\n  'w': '小賢しい',\n  'y': 'コザカシイ',\n  's': 2.094995582103729,\n  'c': [{'i': 185829, 'w': '小ざかしい'}]},\n {'i': 232998, 'w': '俊秀', 'y': 'シュンシュウ', 's': 1.232024323940277, 'c': []},\n {'i': 181812,\n  'w': 'インテリジェント',\n  'y': 'インテリジェント',\n  's': 1.1395291894674302,\n  'c': []},\n {'i': 245325, 'w': '明哲', 'y': 'メイテツ', 's': 1.1395291894674302, 'c': []},\n {'i': 202288, 'w': 'すすどい', 'y': 'ススドイ', 's': 1.0474977910518646, 'c': []}]"},"metadata":{},"output_type":"display_data"}],"source":"def test_synonyms(search: str, top_n:int = 10):\n    tops = get_top_n_percentile(get_mixed_synonyms(search, use_similar=True, similar_boost=0.1), percentile=0.95)\n    display(aggregate_by_yomi(search,tops))\ntest_synonyms(\"賢い\")"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"\ndisplay(get_words_in_all_synsets(\"明るい\"))\nsynonyms = list_synoyms_from_wordnet_dict(\"やる気\")\ndisplay(synonyms)\nlist_neigbhors_from_synonyms(synonyms, topn=20)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def list_neigbhors_from_synonyms(\n    synonyms: Iterable[Tuple[str, int]],\n    topn: int = 100\n):\n    multiplied_list = [[word for i in range(0,occurrence)] for (word, occurrence) in synonyms ]\n    search_list = [word for word_pack in multiplied_list for word in word_pack]\n    # display(search_list)\n    return list_neigbhors_for_search_list(search_list, topn=topn)\n"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def append_neigbhorness_lift_for_each_search(\n    search_list: Iterable[str],\n    word: str,\n    neigbhorness: float\n) -> List[Tuple[str, float, Tuple[float, float]]]:\n    neigbohr_and_lift = []\n    for search in search_list:\n        similarity = model.wv.similarity(word, search)\n        lift =  neigbhorness/similarity if similarity > 0 else 0\n        neigbohr_and_lift += [(similarity, lift)]\n    return (word, neigbhorness, neigbohr_and_lift)"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def filter_neigbours_by_score_func(\n    neigbhorness_lift: Iterable[Tuple[str, float, Tuple[float, float]]],\n    score_func: Callable[float, Iterable[Tuple[float, float]]]):\n"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"unexpected EOF while parsing (<ipython-input-14-bced9ec0ec98>, line 1)","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-bced9ec0ec98>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def get_related_words_with_lifts(search_list: list,\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"searches = [\"明るい\", \"性格\"]\ncombi = [\n   (word, score, [model.wv.similarity(word, search) for search in searches])\n   for (word, score) in model.wv.most_similar(\n       positive=searches,\n       topn=100\n    )\n]\ncoocs = [*filter(None, [\n    None if len([*filter(lambda x: x > score, search_scores)]) > 0 else\n    (\n        word,\n        score,\n        min([*map(lambda x:score/x, search_scores)]),\n        search_scores,\n    )\n    for (word, score, search_scores) in combi]\n)]\ndisplay(\"related\")\ndisplay([*sorted(coocs, key=lambda x:-x[2])][0:50])"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}