{"cells":[{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":"import gensim\nimport sqlite3\nimport Levenshtein\nfrom scipy.stats.mstats import gmean\nimport functools\nfrom typing import Callable, Iterable, List, Set, Dict, Tuple, Optional"},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"/Users/ec2-user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n  \"\"\"Entry point for launching an IPython kernel.\n"}],"source":"model = gensim.models.FastText.load_fasttext_format(\"./data/ja_model.bin\")"},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":"conn = sqlite3.connect(\"./data/wnjpn.db\")"},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":"def get_words_in_all_synsets(\n    search: str or Iterable[str], threshold: int = 1\n) -> List[Tuple[str, int]]:\n    placeholder = \"?\" if type(search) is str else \",\".join([\n        \"?\" for i in range(0, len(search))\n    ])\n    params = (search,threshold) if type (search) is str else [*search, threshold]\n    # print(placeholder, params)\n    cur = conn.execute(f\"\"\"\\\nselect\n sub.lemma,\n count(sub.lemma) as c\nfrom (\n    select\n        related_word.wordid,\n        related_word.lemma\n    from word base\n    inner join sense attributed_sense\n        on attributed_sense.wordid = base.wordid\n    inner join sense all_sense\n        on all_sense.synset = attributed_sense.synset\n    inner join word related_word\n        on related_word.wordid = all_sense.wordid\n        and related_word.lang = \"jpn\"\n    where base.lemma in ({placeholder})\n) sub\ngroup by sub.lemma\nhaving count(sub.lemma) >= (?)\norder by count(sub.lemma) desc\n\"\"\", params)\n    return list(map(lambda x:(x[0], x[1]), cur.fetchall()))\n\n# get_words_in_all_synsets(\"優しい\", 1)\n# get_words_in_all_synsets([\"優しい\", \"好青年\", \"朗らか\"], 2)"},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":"# TODO:　where in でまとめない\ndef create_values_query(neigbhor_list: Iterable[Tuple[str, float]]):\n    params = functools.reduce(\n        lambda acc,e: { **acc, f\"w{e[0]}\": e[1][0], f\"s{e[0]}\": e[1][1] },\n        enumerate(neigbhor_list),\n        {}\n    )\n    query_elems = [f\":w{i}, :s{i}\" for i in range(0, len(neigbhor_list))]\n    return (f\"\"\"select {\" union select \".join(query_elems)} \"\"\", params)\n\ndef get_synonym_score_for_neigbhor_list(\n    neigbhor_list: Iterable[Tuple[str, float]],\n    threshold: int = 1,\n    includes_self: bool = True,\n) -> List[Tuple[str, float]]:\n    (values_query, params) = create_values_query(neigbhor_list)\n    query = f\"\"\"\\\nwith neigbhors(word, score) as (\n{values_query}\n),\nsub(word, score, lemma) as (\nselect\n  n.word,\n  n.score,\n  rel_w.lemma\nfrom neigbhors n\ninner join word w\n  on w.lemma = n.word\ninner join sense s\n  on s.wordid = w.wordid\ninner join sense rel_s\n  on rel_s.synset = s.synset\n  {\"\" if includes_self else \"rel_s.wordid != s.wordid\" }\ninner join word rel_w\n  on rel_w.wordid = rel_s.wordid\n  and rel_w.lang = \"jpn\"\n)\nselect\n sub.lemma,\n sum(sub.score) as score,\n count(sub.lemma) as occurrence\nfrom sub\ngroup by sub.lemma\nhaving count(sub.lemma) >= :threshold\norder by count(sub.lemma) desc\\\n\"\"\"\n    cur = conn.execute(query, {**params, \"threshold\": threshold })\n    return list(map(lambda x:(x[0], x[1], x[2]), cur.fetchall()))\n\n# get_synonym_score_for_neigbhor_list([(\"優しい\",  0.1), (\"朗らか\", 0.01)])"},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'search' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-c47c39c1ab41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.wv.most_similar(\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'search' is not defined"]}],"source":"model.wv.most_similar(\n        positive=search,\n        topn=topn,\n    )\n    \ndef list_synonyms_from_similar_words(\n    search: str,\n    topn: int=20,\n    threshold: int = 1,\n    includes_self: bool = True,\n) -> List[Tuple[str, float, int]]:\n    display(10)\n    neigbhor_list= model.wv.most_similar(\n        positive=search,\n        topn=topn,\n    )\n    display(neigbhor_list)\n    # # similar_words = [*map(lambda x:x[0],neigbhor_list)]\n    # synonyms = get_synonym_score_for_neigbhor_list(\n    #     neigbhor_list=neigbhor_list,\n    #     threshold=threshold,\n    #     includes_self=includes_self,\n    # )\n    return neigbhor_list\n\nlist_synonyms_from_similar_words(search=\"朗らか\")"},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"list_synonyms_from_similar_words() got an unexpected keyword argument 'min_levenstein_dist'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-41c583feba64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#scored = dict(all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mget_mixed_synonyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"素直\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-43-41c583feba64>\u001b[0m in \u001b[0;36mget_mixed_synonyms\u001b[0;34m(search, search_threshold, similar_topn, similar_min_levenstein_dist, similar_boost, similar_threshold)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimilar_topn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmin_levenstein_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimilar_min_levenstein_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimilar_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     modified_score_from_similar_words = [\n","\u001b[0;31mTypeError\u001b[0m: list_synonyms_from_similar_words() got an unexpected keyword argument 'min_levenstein_dist'"]}],"source":"def get_mixed_synonyms(\n    search: str,\n    search_threshold: int=1,\n    similar_topn: int=20,\n    similar_min_levenstein_dist: int=2,\n    similar_boost: float=0.2,\n    similar_threshold: int=1,\n) -> List[Tuple[str, float]]:\n    synoyms_from_search = get_words_in_all_synsets(\n        search=search,\n        threshold=search_threshold,\n    )\n    synonyms_from_similar_words = list_synonyms_from_similar_words(\n        search=search,\n        topn=similar_topn,\n        min_levenstein_dist=similar_min_levenstein_dist,\n        threshold=similar_threshold,\n    )\n    modified_score_from_similar_words = [\n        (word, similar_boost*occurrence) for (word, occurrence) in synonyms_from_similar_words\n    ]\n    score_dict = functools.reduce(\n        lambda acc, x: {**acc, x[0]: (x[1] if x[0] not in acc else acc[x[0]]+ x[1]) },\n        synoyms_from_search + modified_score_from_similar_words,\n        {}\n    )\n    return sorted(score_dict.items(), key=lambda x: x[1], reverse=True)\n    #synonyms_from_similar_words + modified_score_from_similar_words\n    #all_words=[*map(lambda x:x[0], synoyms_from_search)]+[*map(lambda x:x[0], synoyms_from_search)]\n    #scored = dict(all\n\nget_mixed_synonyms(\"素直\")"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"\ndisplay(get_words_in_all_synsets(\"明るい\"))\nsynonyms = list_synoyms_from_wordnet_dict(\"やる気\")\ndisplay(synonyms)\nlist_neigbhors_from_synonyms(synonyms, topn=20)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def list_neigbhors_from_synonyms(\n    synonyms: Iterable[Tuple[str, int]],\n    topn: int = 100\n):\n    multiplied_list = [[word for i in range(0,occurrence)] for (word, occurrence) in synonyms ]\n    search_list = [word for word_pack in multiplied_list for word in word_pack]\n    # display(search_list)\n    return list_neigbhors_for_search_list(search_list, topn=topn)\n"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def append_neigbhorness_lift_for_each_search(\n    search_list: Iterable[str],\n    word: str,\n    neigbhorness: float\n) -> List[Tuple[str, float, Tuple[float, float]]]:\n    neigbohr_and_lift = []\n    for search in search_list:\n        similarity = model.wv.similarity(word, search)\n        lift =  neigbhorness/similarity if similarity > 0 else 0\n        neigbohr_and_lift += [(similarity, lift)]\n    return (word, neigbhorness, neigbohr_and_lift)"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"def filter_neigbours_by_score_func(\n    neigbhorness_lift: Iterable[Tuple[str, float, Tuple[float, float]]],\n    score_func: Callable[float, Iterable[Tuple[float, float]]]):\n"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"unexpected EOF while parsing (<ipython-input-14-bced9ec0ec98>, line 1)","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-bced9ec0ec98>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def get_related_words_with_lifts(search_list: list,\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"searches = [\"明るい\", \"性格\"]\ncombi = [\n   (word, score, [model.wv.similarity(word, search) for search in searches])\n   for (word, score) in model.wv.most_similar(\n       positive=searches,\n       topn=100\n    )\n]\ncoocs = [*filter(None, [\n    None if len([*filter(lambda x: x > score, search_scores)]) > 0 else\n    (\n        word,\n        score,\n        min([*map(lambda x:score/x, search_scores)]),\n        search_scores,\n    )\n    for (word, score, search_scores) in combi]\n)]\ndisplay(\"related\")\ndisplay([*sorted(coocs, key=lambda x:-x[2])][0:50])"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}